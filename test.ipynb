{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = YOLO(\"best_v11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 10.0ms\n",
      "Speed: 13.5ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.3ms\n",
      "Speed: 0.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.5ms\n",
      "Speed: 0.9ms preprocess, 8.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.1ms\n",
      "Speed: 0.8ms preprocess, 8.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.4ms\n",
      "Speed: 0.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 8.4ms\n",
      "Speed: 0.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 7.9ms\n",
      "Speed: 0.8ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/wx_pc/Desktop/yolo_detect_qt/download.jpeg: 384x640 1 landslide, 11 stones, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    results = yolo_model.track(\"download.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])\n",
      "conf: tensor([0.9652, 0.9202, 0.9183, 0.9159, 0.9121, 0.8957, 0.8915, 0.8889, 0.8826, 0.8769, 0.8746, 0.8667])\n",
      "data: tensor([[  0.0000,  47.5548,  99.0416, 167.8971,   1.0000,   0.9652,   1.0000],\n",
      "        [  8.1375, 141.0592,  47.3554, 166.7498,   2.0000,   0.9202,   3.0000],\n",
      "        [119.8238,  93.4806, 146.0028, 118.1169,   3.0000,   0.9183,   3.0000],\n",
      "        [ 45.5752, 100.5313,  82.1427, 122.5206,   4.0000,   0.9159,   3.0000],\n",
      "        [ 10.2129,  82.6867,  31.7527, 106.8553,   5.0000,   0.9121,   3.0000],\n",
      "        [ 31.4374,  88.5034,  56.1553, 103.4897,   6.0000,   0.8957,   3.0000],\n",
      "        [ 21.9125,  73.8932,  43.7993,  88.4444,   7.0000,   0.8915,   3.0000],\n",
      "        [ 76.4276,  80.7502,  94.1883,  96.2810,   8.0000,   0.8889,   3.0000],\n",
      "        [ 11.0400, 103.4143,  41.1293, 122.8162,   9.0000,   0.8826,   3.0000],\n",
      "        [  0.0000,  58.2562,  23.1165,  83.3497,  10.0000,   0.8769,   3.0000],\n",
      "        [ 49.8715, 128.4291,  64.6898, 139.8472,  11.0000,   0.8746,   3.0000],\n",
      "        [ 23.3827, 119.0774,  40.0850, 127.4531,  12.0000,   0.8667,   3.0000]])\n",
      "id: tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n",
      "is_track: True\n",
      "orig_shape: (168, 300)\n",
      "shape: torch.Size([12, 7])\n",
      "xywh: tensor([[ 49.5208, 107.7260,  99.0416, 120.3423],\n",
      "        [ 27.7464, 153.9045,  39.2179,  25.6906],\n",
      "        [132.9133, 105.7987,  26.1790,  24.6363],\n",
      "        [ 63.8590, 111.5260,  36.5675,  21.9893],\n",
      "        [ 20.9828,  94.7710,  21.5398,  24.1686],\n",
      "        [ 43.7964,  95.9966,  24.7179,  14.9863],\n",
      "        [ 32.8559,  81.1688,  21.8868,  14.5511],\n",
      "        [ 85.3080,  88.5156,  17.7607,  15.5308],\n",
      "        [ 26.0847, 113.1153,  30.0893,  19.4018],\n",
      "        [ 11.5582,  70.8030,  23.1165,  25.0935],\n",
      "        [ 57.2806, 134.1382,  14.8183,  11.4182],\n",
      "        [ 31.7339, 123.2652,  16.7023,   8.3758]])\n",
      "xywhn: tensor([[0.1651, 0.6412, 0.3301, 0.7163],\n",
      "        [0.0925, 0.9161, 0.1307, 0.1529],\n",
      "        [0.4430, 0.6298, 0.0873, 0.1466],\n",
      "        [0.2129, 0.6638, 0.1219, 0.1309],\n",
      "        [0.0699, 0.5641, 0.0718, 0.1439],\n",
      "        [0.1460, 0.5714, 0.0824, 0.0892],\n",
      "        [0.1095, 0.4831, 0.0730, 0.0866],\n",
      "        [0.2844, 0.5269, 0.0592, 0.0924],\n",
      "        [0.0869, 0.6733, 0.1003, 0.1155],\n",
      "        [0.0385, 0.4214, 0.0771, 0.1494],\n",
      "        [0.1909, 0.7984, 0.0494, 0.0680],\n",
      "        [0.1058, 0.7337, 0.0557, 0.0499]])\n",
      "xyxy: tensor([[  0.0000,  47.5548,  99.0416, 167.8971],\n",
      "        [  8.1375, 141.0592,  47.3554, 166.7498],\n",
      "        [119.8238,  93.4806, 146.0028, 118.1169],\n",
      "        [ 45.5752, 100.5313,  82.1427, 122.5206],\n",
      "        [ 10.2129,  82.6867,  31.7527, 106.8553],\n",
      "        [ 31.4374,  88.5034,  56.1553, 103.4897],\n",
      "        [ 21.9125,  73.8932,  43.7993,  88.4444],\n",
      "        [ 76.4276,  80.7502,  94.1883,  96.2810],\n",
      "        [ 11.0400, 103.4143,  41.1293, 122.8162],\n",
      "        [  0.0000,  58.2562,  23.1165,  83.3497],\n",
      "        [ 49.8715, 128.4291,  64.6898, 139.8472],\n",
      "        [ 23.3827, 119.0774,  40.0850, 127.4531]])\n",
      "xyxyn: tensor([[0.0000, 0.2831, 0.3301, 0.9994],\n",
      "        [0.0271, 0.8396, 0.1579, 0.9926],\n",
      "        [0.3994, 0.5564, 0.4867, 0.7031],\n",
      "        [0.1519, 0.5984, 0.2738, 0.7293],\n",
      "        [0.0340, 0.4922, 0.1058, 0.6360],\n",
      "        [0.1048, 0.5268, 0.1872, 0.6160],\n",
      "        [0.0730, 0.4398, 0.1460, 0.5265],\n",
      "        [0.2548, 0.4807, 0.3140, 0.5731],\n",
      "        [0.0368, 0.6156, 0.1371, 0.7310],\n",
      "        [0.0000, 0.3468, 0.0771, 0.4961],\n",
      "        [0.1662, 0.7645, 0.2156, 0.8324],\n",
      "        [0.0779, 0.7088, 0.1336, 0.7586]])\n"
     ]
    }
   ],
   "source": [
    "# Get the boxes and track IDs\n",
    "boxes = results[0].boxes\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landslide\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n",
      "stone\n"
     ]
    }
   ],
   "source": [
    "classes = results[0].boxes.cls\n",
    "for cls in classes:\n",
    "    print(results[0].names.get(int(cls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "bbox = results[0].boxes.cls.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, track_history = utils.store_track_info(track_ids,bbox, track_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {(1, 1): [1],\n",
       "             (2, 3): [2],\n",
       "             (3, 3): [3],\n",
       "             (4, 3): [4],\n",
       "             (5, 3): [5],\n",
       "             (6, 3): [6],\n",
       "             (7, 3): [7],\n",
       "             (8, 3): [8],\n",
       "             (9, 3): [9],\n",
       "             (10, 3): [10],\n",
       "             (11, 3): [11],\n",
       "             (12, 3): [12]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapped dictionary: {'stone': 0, 'landslide': 1, 'fallen tree': 0, 'road collapse': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'stone': 0, 'landslide': 1, 'fallen tree': 0, 'road collapse': 11}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences for each class (using just the first element as the \"class\")\n",
    "class_counts = defaultdict(int)\n",
    "dict_count = dict(utils.count_from_track_history(track_history))\n",
    "utils.remap_dictionary(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'fallen tree', 1: 'landslide', 2: 'road collapse', 3: 'stone'}\n",
       "obb: None\n",
       "orig_img: array([[[  8,  28,  33],\n",
       "        [  8,  28,  33],\n",
       "        [ 26,  42,  48],\n",
       "        ...,\n",
       "        [181, 172, 168],\n",
       "        [203, 192, 188],\n",
       "        [143, 132, 128]],\n",
       "\n",
       "       [[ 32,  51,  56],\n",
       "        [ 24,  43,  48],\n",
       "        [ 26,  42,  48],\n",
       "        ...,\n",
       "        [176, 167, 163],\n",
       "        [182, 173, 170],\n",
       "        [255, 253, 249]],\n",
       "\n",
       "       [[ 33,  49,  55],\n",
       "        [ 27,  43,  49],\n",
       "        [ 28,  42,  48],\n",
       "        ...,\n",
       "        [140, 133, 130],\n",
       "        [198, 190, 190],\n",
       "        [215, 208, 205]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 20,  36,  53],\n",
       "        [ 17,  33,  50],\n",
       "        [ 23,  39,  56],\n",
       "        ...,\n",
       "        [105, 110, 119],\n",
       "        [102, 107, 116],\n",
       "        [ 98, 103, 112]],\n",
       "\n",
       "       [[ 47,  63,  80],\n",
       "        [ 41,  57,  74],\n",
       "        [ 44,  60,  77],\n",
       "        ...,\n",
       "        [114, 119, 128],\n",
       "        [113, 118, 127],\n",
       "        [113, 118, 127]],\n",
       "\n",
       "       [[ 17,  33,  50],\n",
       "        [ 22,  38,  55],\n",
       "        [ 38,  54,  71],\n",
       "        ...,\n",
       "        [113, 118, 127],\n",
       "        [111, 116, 125],\n",
       "        [109, 114, 123]]], dtype=uint8)\n",
       "orig_shape: (168, 300)\n",
       "path: '/home/wx_pc/Desktop/yolo_detect_qt/download.jpeg'\n",
       "probs: None\n",
       "save_dir: 'runs/detect/track'\n",
       "speed: {'preprocess': 0.8983612060546875, 'inference': 7.926225662231445, 'postprocess': 0.835418701171875}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "if (results[0].boxes.id) is not None:\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Sample data\n",
    "data = defaultdict(lambda: [],\n",
    "    {\n",
    "        (1, 1.0): [1, 1, 1],\n",
    "        (2, 3.0): [2, 2, 2],\n",
    "        (3, 3.0): [3, 3, 3],\n",
    "        (4, 3.0): [4, 4, 4],\n",
    "        (5, 3.0): [5, 5, 5],\n",
    "        (6, 3.0): [6, 6, 6],\n",
    "        (7, 3.0): [7, 7, 7],\n",
    "        (8, 3.0): [8, 8, 8],\n",
    "        (9, 3.0): [9, 9, 9],\n",
    "        (10, 3.0): [10, 10, 10],\n",
    "        (11, 3.0): [11, 11, 11],\n",
    "        (12, 3.0): [12, 12, 12]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
